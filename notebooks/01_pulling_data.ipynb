{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Energy Forecasting Using PVGIS Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project focuses on analyzing historical solar irradiance and meteorological data to explore trends, correlations, and potential applications in renewable energy forecasting. The data is retrieved from the [Photovoltaic Geographical Information System (PVGIS)](https://joint-research-centre.ec.europa.eu/photovoltaic-geographical-information-system-pvgis/pvgis-tools/hourly-radiation_en), an open-source resource provided by the European Commission's Joint Research Centre.\n",
    "\n",
    "### Data Source\n",
    "The dataset is fetched using the PVGIS API and includes key parameters such as:\n",
    "- **Global in-plane irradiance (G(i))**: Measured in W\\m2\n",
    "- **Sun height (H_sun)**: Measured in °\n",
    "- **Air temperature (T2m)**: Measured in °C\n",
    "- **Wind speed (WS10m)**: Measured in m/s at 10m\n",
    "\n",
    "### Project Goal\n",
    "The objective is to preprocess, analyze, and potentially build models that can predict solar energy availability based on historical weather conditions. This can be useful for solar power generation forecasting and energy management.\n",
    "\n",
    "### First Code Cell: Fetching PVGIS Data\n",
    "The first code cell retrieves hourly solar radiation and meteorological data for a location (Berlin, lat=52.52, lon=13.41) via an API request. It processes the response to extract relevant information and loads it into a structured DataFrame for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response code:  200\n",
      "Extracted column_names:  ['time', 'G(i)', 'H_sun', 'T2m', 'WS10m', 'Int']\n",
      "Generated df:                  time  G(i)  H_sun   T2m  WS10m  Int\n",
      "0      20050101:0011   0.0    0.0  6.83   3.59  0.0\n",
      "1      20050101:0111   0.0    0.0  6.80   3.45  0.0\n",
      "2      20050101:0211   0.0    0.0  6.79   3.24  0.0\n",
      "3      20050101:0311   0.0    0.0  6.44   2.83  0.0\n",
      "4      20050101:0411   0.0    0.0  6.26   2.62  0.0\n",
      "...              ...   ...    ...   ...    ...  ...\n",
      "17515  20061231:1911   0.0    0.0  8.33   4.21  0.0\n",
      "17516  20061231:2011   0.0    0.0  8.58   4.21  0.0\n",
      "17517  20061231:2111   0.0    0.0  8.24   4.48  0.0\n",
      "17518  20061231:2211   0.0    0.0  7.70   4.76  0.0\n",
      "17519  20061231:2311   0.0    0.0  7.18   4.83  0.0\n",
      "\n",
      "[17520 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# API URL\n",
    "url = \"https://re.jrc.ec.europa.eu/api/v5_2/seriescalc?lat=52.52&lon=13.41&startyear=2005&endyear=2006&outputformat=csv\"\n",
    "\n",
    "# Fetch data\n",
    "response = requests.get(url)\n",
    "\n",
    "print(\"response code: \", response.status_code)\n",
    "\n",
    "# Check if the response is valid\n",
    "if response.status_code == 200:\n",
    "    try:\n",
    "        # Split the response into lines\n",
    "        lines = response.text.split(\"\\n\")\n",
    "\n",
    "        #column_names = []\n",
    "        header_metadata = []\n",
    "        data_lines = []\n",
    "        header_found = False\n",
    "\n",
    "        footer_metadata = []\n",
    "        data_cleaned = []\n",
    "\n",
    "        for line in lines:\n",
    "            if line.startswith(\"time\"):\n",
    "                header_found = True\n",
    "                column_names = line.strip().split(\",\")\n",
    "                data_lines.append(line)\n",
    "                continue\n",
    "            if not header_found:\n",
    "                header_metadata.append(line)\n",
    "            else:\n",
    "                data_lines.append(line)\n",
    "\n",
    "        for row in data_lines:\n",
    "            if any(c.isalpha() for c in row) and not row.startswith(\"time\"):\n",
    "                footer_metadata.append(row)\n",
    "            else:\n",
    "                data_cleaned.append(row)\n",
    "\n",
    "        print(\"Extracted column_names: \", column_names)\n",
    "\n",
    "        csv_data = \"\\n\".join(data_cleaned)\n",
    "        df = pd.read_csv(StringIO(csv_data), names=column_names, header=0)\n",
    "        print(\"Generated df: \", df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error while parsing CSV:\", str(e))\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n",
    "\n",
    "\n",
    "with open(\"solar_data.pkl\", \"wb\") as file:\n",
    "    pickle.dump(df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
